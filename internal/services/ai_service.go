package services

import (
	"bytes"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net/http"
	"strings"
	"time"

	"github.com/EasyPeek/EasyPeek-backend/internal/config"
	"github.com/EasyPeek/EasyPeek-backend/internal/models"
	"gorm.io/gorm"
)

// AIProvider AIæä¾›å•†æ¥å£
type AIProvider interface {
	GenerateSummary(content string) (string, error)
	ExtractKeywords(content string) ([]string, error)
	AnalyzeSentiment(content string) (string, float64, error)
	AnalyzeEvent(content string, context string) (*EventAnalysisResult, error)
	PredictTrends(content string, historicalData []models.News) ([]models.TrendPrediction, error)
}

// EventAnalysisResult äº‹ä»¶åˆ†æç»“æœ
type EventAnalysisResult struct {
	Analysis      string
	ImpactLevel   string
	ImpactScore   float64
	ImpactScope   string
	RelatedTopics []string
	Steps         []models.AnalysisStep
}

// AIService AIæœåŠ¡
type AIService struct {
	db       *gorm.DB
	provider AIProvider
}

// NewAIService åˆ›å»ºAIæœåŠ¡å®ä¾‹
func NewAIService(db *gorm.DB) *AIService {
	provider := NewOpenAICompatibleProvider()
	return &AIService{
		db:       db,
		provider: provider,
	}
}

// NewAIServiceWithConfig ä½¿ç”¨æŒ‡å®šé…ç½®åˆ›å»ºAIæœåŠ¡å®ä¾‹
func NewAIServiceWithConfig(db *gorm.DB, cfg *config.Config) *AIService {
	provider := NewOpenAICompatibleProviderWithConfig(cfg)
	return &AIService{
		db:       db,
		provider: provider,
	}
}

// AnalyzeNews åˆ†ææ–°é—»
func (s *AIService) AnalyzeNews(newsID uint, options models.AIAnalysisRequest) (*models.AIAnalysis, error) {
	startTime := time.Now()

	// è·å–æ–°é—»æ•°æ®
	var news models.News
	if err := s.db.First(&news, newsID).Error; err != nil {
		return nil, fmt.Errorf("æ–°é—»æœªæ‰¾åˆ°: %w", err)
	}

	// æ£€æŸ¥æ˜¯å¦å·²æœ‰åˆ†æç»“æœ
	var existingAnalysis models.AIAnalysis
	if err := s.db.Where("type = ? AND target_id = ?", models.AIAnalysisTypeNews, newsID).First(&existingAnalysis).Error; err == nil {
		// å¦‚æœå·²æœ‰åˆ†æä¸”çŠ¶æ€ä¸ºcompletedï¼Œç›´æ¥è¿”å›
		if existingAnalysis.Status == "completed" {
			return &existingAnalysis, nil
		}
	}

	// åˆ›å»ºæ–°çš„åˆ†æè®°å½•
	analysis := &models.AIAnalysis{
		Type:         models.AIAnalysisTypeNews,
		TargetID:     newsID,
		Status:       "processing",
		ModelName:    s.provider.(*OpenAICompatibleProvider).model, // ä»é…ç½®è¯»å–æ¨¡å‹åç§°
		ModelVersion: "v1",
	}

	// ä¿å­˜åˆå§‹è®°å½•
	if err := s.db.Create(analysis).Error; err != nil {
		return nil, fmt.Errorf("åˆ›å»ºåˆ†æè®°å½•å¤±è´¥: %w", err)
	}

	// å‡†å¤‡åˆ†æå†…å®¹
	content := news.Title + "\n\n" + news.Content
	if news.Description != "" {
		content = news.Title + "\n\n" + news.Description + "\n\n" + news.Content
	}

	analysisSteps := []models.AnalysisStep{}
	stepCount := 1

	// 1. ç”Ÿæˆæ‘˜è¦
	if options.Options.EnableSummary {
		summary, err := s.provider.GenerateSummary(content)
		if err != nil {
			s.updateAnalysisStatus(analysis.ID, "failed", 0)
			return nil, fmt.Errorf("ç”Ÿæˆæ‘˜è¦å¤±è´¥: %w", err)
		}
		analysis.Summary = summary
		analysisSteps = append(analysisSteps, models.AnalysisStep{
			Step:        stepCount,
			Title:       "å†…å®¹æ‘˜è¦æå–",
			Description: "ä½¿ç”¨AIæ¨¡å‹å¯¹æ–°é—»å†…å®¹è¿›è¡Œæ‘˜è¦æå–",
			Result:      "å·²ç”Ÿæˆç®€æ´çš„æ–°é—»æ‘˜è¦",
			Confidence:  0.95,
		})
		stepCount++
	}

	// 2. æå–å…³é”®è¯
	if options.Options.EnableKeywords {
		keywords, err := s.provider.ExtractKeywords(content)
		if err != nil {
			s.updateAnalysisStatus(analysis.ID, "failed", 0)
			return nil, fmt.Errorf("æå–å…³é”®è¯å¤±è´¥: %w", err)
		}
		keywordsJSON, _ := json.Marshal(keywords)
		analysis.Keywords = string(keywordsJSON)
		analysisSteps = append(analysisSteps, models.AnalysisStep{
			Step:        stepCount,
			Title:       "å…³é”®è¯æå–",
			Description: "ä»æ–°é—»å†…å®¹ä¸­æå–æ ¸å¿ƒå…³é”®è¯",
			Result:      fmt.Sprintf("æå–åˆ°%dä¸ªå…³é”®è¯", len(keywords)),
			Confidence:  0.92,
		})
		stepCount++
	}

	// 3. æƒ…æ„Ÿåˆ†æ
	if options.Options.EnableSentiment {
		sentiment, score, err := s.provider.AnalyzeSentiment(content)
		if err != nil {
			s.updateAnalysisStatus(analysis.ID, "failed", 0)
			return nil, fmt.Errorf("æƒ…æ„Ÿåˆ†æå¤±è´¥: %w", err)
		}
		analysis.Sentiment = sentiment
		analysis.SentimentScore = score
		analysisSteps = append(analysisSteps, models.AnalysisStep{
			Step:        stepCount,
			Title:       "æƒ…æ„Ÿå€¾å‘åˆ†æ",
			Description: "åˆ†ææ–°é—»å†…å®¹çš„æƒ…æ„Ÿå€¾å‘",
			Result:      fmt.Sprintf("æƒ…æ„Ÿå€¾å‘: %s (å¾—åˆ†: %.2f)", sentiment, score),
			Confidence:  0.88,
		})
		stepCount++
	}

	// 4. äº‹ä»¶åˆ†æå’Œå½±å“åŠ›è¯„ä¼°
	if options.Options.EnableImpact {
		// è·å–ç›¸å…³å†å²æ–°é—»ä½œä¸ºä¸Šä¸‹æ–‡
		var relatedNews []models.News
		s.db.Where("category = ? AND id != ?", news.Category, news.ID).
			Order("published_at DESC").
			Limit(10).
			Find(&relatedNews)

		context := s.buildContext(relatedNews)
		eventResult, err := s.provider.AnalyzeEvent(content, context)
		if err != nil {
			s.updateAnalysisStatus(analysis.ID, "failed", 0)
			return nil, fmt.Errorf("äº‹ä»¶åˆ†æå¤±è´¥: %w", err)
		}

		analysis.EventAnalysis = eventResult.Analysis
		analysis.ImpactLevel = eventResult.ImpactLevel
		analysis.ImpactScore = eventResult.ImpactScore
		analysis.ImpactScope = eventResult.ImpactScope

		topicsJSON, _ := json.Marshal(eventResult.RelatedTopics)
		analysis.RelatedTopics = string(topicsJSON)

		analysisSteps = append(analysisSteps, models.AnalysisStep{
			Step:        stepCount,
			Title:       "äº‹ä»¶å½±å“åŠ›åˆ†æ",
			Description: "è¯„ä¼°äº‹ä»¶çš„æ½œåœ¨å½±å“åŠ›å’ŒèŒƒå›´",
			Result:      fmt.Sprintf("å½±å“çº§åˆ«: %s, å½±å“åŠ›åˆ†æ•°: %.2f", eventResult.ImpactLevel, eventResult.ImpactScore),
			Confidence:  0.85,
		})
		stepCount++

		// æ·»åŠ AIç”Ÿæˆçš„åˆ†ææ­¥éª¤
		analysisSteps = append(analysisSteps, eventResult.Steps...)
	}

	// 5. è¶‹åŠ¿é¢„æµ‹
	if options.Options.EnableTrends {
		// è·å–å†å²æ•°æ®
		var historicalNews []models.News
		s.db.Where("category = ?", news.Category).
			Order("published_at DESC").
			Limit(20).
			Find(&historicalNews)

		predictions, err := s.provider.PredictTrends(content, historicalNews)
		if err != nil {
			s.updateAnalysisStatus(analysis.ID, "failed", 0)
			return nil, fmt.Errorf("è¶‹åŠ¿é¢„æµ‹å¤±è´¥: %w", err)
		}

		analysis.TrendPredictions = predictions
		analysisSteps = append(analysisSteps, models.AnalysisStep{
			Step:        stepCount,
			Title:       "æœªæ¥è¶‹åŠ¿é¢„æµ‹",
			Description: "åŸºäºå†å²æ•°æ®å’Œå½“å‰äº‹ä»¶é¢„æµ‹æœªæ¥å‘å±•è¶‹åŠ¿",
			Result:      fmt.Sprintf("ç”Ÿæˆäº†%dä¸ªæ—¶é—´ç»´åº¦çš„è¶‹åŠ¿é¢„æµ‹", len(predictions)),
			Confidence:  0.78,
		})
	}

	// æ›´æ–°åˆ†ææ­¥éª¤
	if options.Options.ShowAnalysisSteps {
		analysis.AnalysisSteps = analysisSteps
	}

	// è®¡ç®—æ•´ä½“ç½®ä¿¡åº¦
	if len(analysisSteps) > 0 {
		totalConfidence := 0.0
		for _, step := range analysisSteps {
			totalConfidence += step.Confidence
		}
		analysis.Confidence = totalConfidence / float64(len(analysisSteps))
	}

	// æ›´æ–°å¤„ç†æ—¶é—´å’ŒçŠ¶æ€
	processingTime := int(time.Since(startTime).Seconds())
	analysis.ProcessingTime = processingTime
	analysis.Status = "completed"

	// ä¿å­˜å®Œæ•´çš„åˆ†æç»“æœ
	if err := s.db.Save(analysis).Error; err != nil {
		return nil, fmt.Errorf("ä¿å­˜åˆ†æç»“æœå¤±è´¥: %w", err)
	}

	// æ›´æ–°æ–°é—»çš„æ‘˜è¦å­—æ®µ
	if analysis.Summary != "" {
		s.db.Model(&news).Update("summary", analysis.Summary)
	}

	return analysis, nil
}

// AnalyzeEvent åˆ†æäº‹ä»¶
func (s *AIService) AnalyzeEvent(eventID uint, options models.AIAnalysisRequest) (*models.AIAnalysis, error) {
	startTime := time.Now()

	// è·å–äº‹ä»¶æ•°æ®
	var event models.Event
	if err := s.db.First(&event, eventID).Error; err != nil {
		return nil, fmt.Errorf("äº‹ä»¶æœªæ‰¾åˆ°: %w", err)
	}

	// æ£€æŸ¥æ˜¯å¦å·²æœ‰åˆ†æç»“æœ
	var existingAnalysis models.AIAnalysis
	if err := s.db.Where("type = ? AND target_id = ?", models.AIAnalysisTypeEvent, eventID).First(&existingAnalysis).Error; err == nil {
		// å¦‚æœå·²æœ‰åˆ†æä¸”çŠ¶æ€ä¸ºcompletedï¼Œç›´æ¥è¿”å›
		if existingAnalysis.Status == "completed" {
			return &existingAnalysis, nil
		}
	}

	// è·å–å…³è”çš„æ–°é—»
	var relatedNews []models.News
	s.db.Where("belonged_event_id = ?", eventID).Find(&relatedNews)

	// æ„å»ºåˆ†æå†…å®¹
	content := s.buildEventContent(event, relatedNews)

	// åˆ›å»ºåˆ†æè®°å½•
	analysis := &models.AIAnalysis{
		Type:         models.AIAnalysisTypeEvent,
		TargetID:     eventID,
		Status:       "processing",
		ModelName:    s.provider.(*OpenAICompatibleProvider).model, // ä»é…ç½®è¯»å–æ¨¡å‹åç§°
		ModelVersion: "v1",
	}

	if err := s.db.Create(analysis).Error; err != nil {
		return nil, fmt.Errorf("åˆ›å»ºåˆ†æè®°å½•å¤±è´¥: %w", err)
	}

	// æ‰§è¡Œåˆ†æï¼ˆç±»ä¼¼æ–°é—»åˆ†ææµç¨‹ï¼‰
	analysisSteps := []models.AnalysisStep{}
	stepCount := 1

	// 1. ç”Ÿæˆæ‘˜è¦
	if options.Options.EnableSummary {
		summary, err := s.provider.GenerateSummary(content)
		if err != nil {
			s.updateAnalysisStatus(analysis.ID, "failed", 0)
			return nil, fmt.Errorf("ç”Ÿæˆæ‘˜è¦å¤±è´¥: %w", err)
		}
		analysis.Summary = summary
		analysisSteps = append(analysisSteps, models.AnalysisStep{
			Step:        stepCount,
			Title:       "äº‹ä»¶æ‘˜è¦æå–",
			Description: "ä½¿ç”¨AIæ¨¡å‹å¯¹äº‹ä»¶å†…å®¹è¿›è¡Œæ‘˜è¦æå–",
			Result:      "å·²ç”Ÿæˆäº‹ä»¶æ‘˜è¦",
			Confidence:  0.95,
		})
		stepCount++
	}

	// 2. æå–å…³é”®è¯
	if options.Options.EnableKeywords {
		keywords, err := s.provider.ExtractKeywords(content)
		if err != nil {
			s.updateAnalysisStatus(analysis.ID, "failed", 0)
			return nil, fmt.Errorf("æå–å…³é”®è¯å¤±è´¥: %w", err)
		}
		keywordsJSON, _ := json.Marshal(keywords)
		analysis.Keywords = string(keywordsJSON)
		analysisSteps = append(analysisSteps, models.AnalysisStep{
			Step:        stepCount,
			Title:       "å…³é”®è¯æå–",
			Description: "ä»äº‹ä»¶å†…å®¹ä¸­æå–æ ¸å¿ƒå…³é”®è¯",
			Result:      fmt.Sprintf("æå–åˆ°%dä¸ªå…³é”®è¯", len(keywords)),
			Confidence:  0.92,
		})
		stepCount++
	}

	// 3. æƒ…æ„Ÿåˆ†æ
	if options.Options.EnableSentiment {
		sentiment, score, err := s.provider.AnalyzeSentiment(content)
		if err != nil {
			s.updateAnalysisStatus(analysis.ID, "failed", 0)
			return nil, fmt.Errorf("æƒ…æ„Ÿåˆ†æå¤±è´¥: %w", err)
		}
		analysis.Sentiment = sentiment
		analysis.SentimentScore = score
		analysisSteps = append(analysisSteps, models.AnalysisStep{
			Step:        stepCount,
			Title:       "æƒ…æ„Ÿå€¾å‘åˆ†æ",
			Description: "åˆ†æäº‹ä»¶çš„æƒ…æ„Ÿå€¾å‘",
			Result:      fmt.Sprintf("æƒ…æ„Ÿå€¾å‘: %s (å¾—åˆ†: %.2f)", sentiment, score),
			Confidence:  0.88,
		})
		stepCount++
	}

	// 4. äº‹ä»¶æ·±åº¦åˆ†æå’Œå½±å“åŠ›è¯„ä¼°
	if options.Options.EnableImpact {
		context := s.buildContext(relatedNews)
		eventResult, err := s.provider.AnalyzeEvent(content, context)
		if err != nil {
			s.updateAnalysisStatus(analysis.ID, "failed", 0)
			return nil, fmt.Errorf("äº‹ä»¶åˆ†æå¤±è´¥: %w", err)
		}

		analysis.EventAnalysis = eventResult.Analysis
		analysis.ImpactLevel = eventResult.ImpactLevel
		analysis.ImpactScore = eventResult.ImpactScore
		analysis.ImpactScope = eventResult.ImpactScope

		topicsJSON, _ := json.Marshal(eventResult.RelatedTopics)
		analysis.RelatedTopics = string(topicsJSON)

		analysisSteps = append(analysisSteps, models.AnalysisStep{
			Step:        stepCount,
			Title:       "äº‹ä»¶å½±å“åŠ›åˆ†æ",
			Description: "è¯„ä¼°äº‹ä»¶çš„æ½œåœ¨å½±å“åŠ›å’ŒèŒƒå›´",
			Result:      fmt.Sprintf("å½±å“çº§åˆ«: %s, å½±å“åŠ›åˆ†æ•°: %.2f", eventResult.ImpactLevel, eventResult.ImpactScore),
			Confidence:  0.85,
		})
		stepCount++

		// æ·»åŠ AIç”Ÿæˆçš„åˆ†ææ­¥éª¤
		analysisSteps = append(analysisSteps, eventResult.Steps...)
	}

	// 5. è¶‹åŠ¿é¢„æµ‹
	if options.Options.EnableTrends {
		// ä½¿ç”¨ç›¸å…³æ–°é—»ä½œä¸ºå†å²æ•°æ®
		predictions, err := s.provider.PredictTrends(content, relatedNews)
		if err != nil {
			s.updateAnalysisStatus(analysis.ID, "failed", 0)
			return nil, fmt.Errorf("è¶‹åŠ¿é¢„æµ‹å¤±è´¥: %w", err)
		}

		analysis.TrendPredictions = predictions
		analysisSteps = append(analysisSteps, models.AnalysisStep{
			Step:        stepCount,
			Title:       "æœªæ¥è¶‹åŠ¿é¢„æµ‹",
			Description: "åŸºäºäº‹ä»¶å’Œç›¸å…³æ–°é—»é¢„æµ‹æœªæ¥å‘å±•è¶‹åŠ¿",
			Result:      fmt.Sprintf("ç”Ÿæˆäº†%dä¸ªæ—¶é—´ç»´åº¦çš„è¶‹åŠ¿é¢„æµ‹", len(predictions)),
			Confidence:  0.78,
		})
	}

	// æ›´æ–°åˆ†ææ­¥éª¤
	if options.Options.ShowAnalysisSteps {
		analysis.AnalysisSteps = analysisSteps
	}

	// è®¡ç®—æ•´ä½“ç½®ä¿¡åº¦
	if len(analysisSteps) > 0 {
		totalConfidence := 0.0
		for _, step := range analysisSteps {
			totalConfidence += step.Confidence
		}
		analysis.Confidence = totalConfidence / float64(len(analysisSteps))
	}

	// æ›´æ–°å¤„ç†æ—¶é—´å’ŒçŠ¶æ€
	analysis.Status = "completed"
	analysis.ProcessingTime = int(time.Since(startTime).Seconds())

	if err := s.db.Save(analysis).Error; err != nil {
		return nil, fmt.Errorf("ä¿å­˜åˆ†æç»“æœå¤±è´¥: %w", err)
	}

	return analysis, nil
}

// GetAnalysis è·å–åˆ†æç»“æœ
func (s *AIService) GetAnalysis(analysisType models.AIAnalysisType, targetID uint) (*models.AIAnalysis, error) {
	var analysis models.AIAnalysis

	// ä¼˜å…ˆè·å–completedçŠ¶æ€çš„æœ€æ–°è®°å½•
	err := s.db.Where("type = ? AND target_id = ? AND status = ?", analysisType, targetID, "completed").
		Order("created_at DESC").
		First(&analysis).Error

	if err != nil {
		// å¦‚æœæ²¡æœ‰completedçš„è®°å½•ï¼Œè·å–æœ€æ–°çš„è®°å½•ï¼ˆå¯èƒ½æ˜¯processingæˆ–failedï¼‰
		err = s.db.Where("type = ? AND target_id = ?", analysisType, targetID).
			Order("created_at DESC").
			First(&analysis).Error
		if err != nil {
			return nil, err
		}
	}

	return &analysis, nil
}

// buildContext æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
func (s *AIService) buildContext(relatedNews []models.News) string {
	var context strings.Builder
	context.WriteString("ç›¸å…³å†å²æ–°é—»:\n")
	for i, news := range relatedNews {
		context.WriteString(fmt.Sprintf("%d. %s (%s)\n", i+1, news.Title, news.PublishedAt.Format("2006-01-02")))
		if news.Summary != "" {
			context.WriteString(fmt.Sprintf("   æ‘˜è¦: %s\n", news.Summary))
		}
	}
	return context.String()
}

// buildEventContent æ„å»ºäº‹ä»¶å†…å®¹
func (s *AIService) buildEventContent(event models.Event, relatedNews []models.News) string {
	var content strings.Builder
	content.WriteString(fmt.Sprintf("äº‹ä»¶æ ‡é¢˜: %s\n", event.Title))
	content.WriteString(fmt.Sprintf("äº‹ä»¶æè¿°: %s\n", event.Description))
	if event.Content != "" {
		content.WriteString(fmt.Sprintf("\näº‹ä»¶è¯¦æƒ…:\n%s\n", event.Content))
	}

	if len(relatedNews) > 0 {
		content.WriteString("\nç›¸å…³æ–°é—»:\n")
		for i, news := range relatedNews {
			content.WriteString(fmt.Sprintf("%d. %s\n", i+1, news.Title))
			if news.Summary != "" {
				content.WriteString(fmt.Sprintf("   %s\n", news.Summary))
			}
		}
	}

	return content.String()
}

// GetProvider è·å–AIæä¾›å•†å®ä¾‹ï¼ˆç”¨äºæµ‹è¯•ï¼‰
func (s *AIService) GetProvider() AIProvider {
	return s.provider
}

// updateAnalysisStatus æ›´æ–°åˆ†æçŠ¶æ€
func (s *AIService) updateAnalysisStatus(analysisID uint, status string, processingTime int) {
	updates := map[string]interface{}{
		"status": status,
	}
	if processingTime > 0 {
		updates["processing_time"] = processingTime
	}
	s.db.Model(&models.AIAnalysis{}).Where("id = ?", analysisID).Updates(updates)
}

// OpenAICompatibleProvider OpenAIå…¼å®¹APIæä¾›å•†
type OpenAICompatibleProvider struct {
	apiKey      string
	baseURL     string
	model       string
	siteURL     string
	siteName    string
	maxTokens   int
	temperature float64
	timeout     int
}

// NewOpenAICompatibleProvider åˆ›å»ºOpenAIå…¼å®¹çš„æä¾›å•†ï¼ˆä½¿ç”¨å…¨å±€é…ç½®ï¼‰
func NewOpenAICompatibleProvider() *OpenAICompatibleProvider {
	return NewOpenAICompatibleProviderWithConfig(config.AppConfig)
}

// NewOpenAICompatibleProviderWithConfig ä½¿ç”¨æŒ‡å®šé…ç½®åˆ›å»ºOpenAIå…¼å®¹çš„æä¾›å•†
func NewOpenAICompatibleProviderWithConfig(cfg *config.Config) *OpenAICompatibleProvider {
	// é»˜è®¤é…ç½® - ä¿®æ”¹ä¸ºOpenRouterçš„é»˜è®¤é…ç½®
	provider := &OpenAICompatibleProvider{
		apiKey:      "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",
		baseURL:     "https://openrouter.ai/api/v1",
		model:       "google/gemini-2.0-flash-001", // ä½¿ç”¨ç¨³å®šçš„thinkingç‰ˆæœ¬
		siteURL:     "http://localhost:5173/",
		siteName:    "EasyPeek",
		maxTokens:   4000,
		temperature: 0.7,
		timeout:     30,
	}

	// å¦‚æœé…ç½®å­˜åœ¨ï¼Œåˆ™ä½¿ç”¨é…ç½®å€¼
	if cfg != nil {
		log.Printf("ğŸ”§ AIé…ç½®åŠ è½½: Provider=%s, Model=%s", cfg.AI.Provider, cfg.AI.Model)
		// ç›´æ¥ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„API Key
		if cfg.AI.APIKey != "" {
			provider.apiKey = cfg.AI.APIKey
			// å®‰å…¨åœ°æ˜¾ç¤ºAPI Keyå‰ç¼€ç”¨äºè°ƒè¯•
			keyPrefix := cfg.AI.APIKey
			if len(keyPrefix) > 20 {
				keyPrefix = keyPrefix[:20] + "..."
			}
			log.Printf("ğŸ”‘ API Keyå·²ä»é…ç½®æ–‡ä»¶åŠ è½½: %s (é•¿åº¦: %d)", keyPrefix, len(cfg.AI.APIKey))
		} else {
			log.Printf("âš ï¸ è­¦å‘Š: é…ç½®æ–‡ä»¶ä¸­API Keyä¸ºç©º: %q", cfg.AI.APIKey)
		}
		if cfg.AI.BaseURL != "" {
			provider.baseURL = cfg.AI.BaseURL
		}
		if cfg.AI.Model != "" {
			provider.model = cfg.AI.Model
		}
		if cfg.AI.SiteURL != "" {
			provider.siteURL = cfg.AI.SiteURL
		}
		if cfg.AI.SiteName != "" {
			provider.siteName = cfg.AI.SiteName
		}
		if cfg.AI.MaxTokens > 0 {
			provider.maxTokens = cfg.AI.MaxTokens
		}
		if cfg.AI.Temperature > 0 {
			provider.temperature = cfg.AI.Temperature
		}
		if cfg.AI.Timeout > 0 {
			provider.timeout = cfg.AI.Timeout
		}
	} else {
		log.Printf("âŒ é”™è¯¯: é…ç½®æ–‡ä»¶æœªåŠ è½½")
	}

	log.Printf("âœ… AI Provideråˆå§‹åŒ–å®Œæˆ - BaseURL: %s, Model: %s", provider.baseURL, provider.model)
	return provider
}

// GenerateSummary ç”Ÿæˆæ‘˜è¦
func (p *OpenAICompatibleProvider) GenerateSummary(content string) (string, error) {
	prompt := fmt.Sprintf(`è¯·ä¸ºä»¥ä¸‹æ–°é—»å†…å®¹ç”Ÿæˆä¸€ä¸ªç®€æ´çš„æ‘˜è¦ï¼ˆä¸è¶…è¿‡200å­—ï¼‰ï¼š

%s

æ‘˜è¦ï¼š`, content)

	response, err := p.callAPI(prompt)
	if err != nil {
		return "", err
	}

	return response, nil
}

// ExtractKeywords æå–å…³é”®è¯
func (p *OpenAICompatibleProvider) ExtractKeywords(content string) ([]string, error) {
	prompt := fmt.Sprintf(`è¯·ä»ä»¥ä¸‹æ–°é—»å†…å®¹ä¸­æå–5-8ä¸ªæœ€é‡è¦çš„å…³é”®è¯ï¼Œç”¨é€—å·åˆ†éš”ï¼š

%s

å…³é”®è¯ï¼š`, content)

	response, err := p.callAPI(prompt)
	if err != nil {
		return nil, err
	}

	// è§£æå…³é”®è¯
	keywords := strings.Split(response, ",")
	for i := range keywords {
		keywords[i] = strings.TrimSpace(keywords[i])
	}

	return keywords, nil
}

// AnalyzeSentiment æƒ…æ„Ÿåˆ†æ
func (p *OpenAICompatibleProvider) AnalyzeSentiment(content string) (string, float64, error) {
	prompt := fmt.Sprintf(`è¯·åˆ†æä»¥ä¸‹æ–°é—»å†…å®¹çš„æƒ…æ„Ÿå€¾å‘ï¼Œè¿”å›æ ¼å¼ä¸º"æƒ…æ„Ÿç±»å‹|åˆ†æ•°"ï¼ˆæƒ…æ„Ÿç±»å‹ï¼špositive/negative/neutralï¼Œåˆ†æ•°ï¼š0-1ï¼‰ï¼š

%s

åˆ†æç»“æœï¼š`, content)

	response, err := p.callAPI(prompt)
	if err != nil {
		return "", 0, err
	}

	// è§£æç»“æœ
	parts := strings.Split(response, "|")
	if len(parts) != 2 {
		return "neutral", 0.5, nil
	}

	sentiment := strings.TrimSpace(parts[0])
	score := 0.5
	fmt.Sscanf(strings.TrimSpace(parts[1]), "%f", &score)

	return sentiment, score, nil
}

// AnalyzeEvent åˆ†æäº‹ä»¶
func (p *OpenAICompatibleProvider) AnalyzeEvent(content string, context string) (*EventAnalysisResult, error) {
	prompt := fmt.Sprintf(`è¯·å¯¹ä»¥ä¸‹æ–°é—»äº‹ä»¶è¿›è¡Œæ·±åº¦åˆ†æï¼š

æ–°é—»å†…å®¹ï¼š
%s

%s

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¿”å›åˆ†æç»“æœï¼ˆä½¿ç”¨JSONæ ¼å¼ï¼‰ï¼š
{
  "analysis": "äº‹ä»¶çš„è¯¦ç»†åˆ†æ",
  "impact_level": "high/medium/low",
  "impact_score": 0.0-10.0,
  "impact_scope": "å½±å“èŒƒå›´æè¿°",
  "related_topics": ["ç›¸å…³è¯é¢˜1", "ç›¸å…³è¯é¢˜2"],
  "analysis_steps": [
    {
      "step": 1,
      "title": "æ­¥éª¤æ ‡é¢˜",
      "description": "æ­¥éª¤æè¿°",
      "result": "æ­¥éª¤ç»“æœ",
      "confidence": 0.0-1.0
    }
  ]
}`, content, context)

	response, err := p.callAPI(prompt)
	if err != nil {
		return nil, err
	}

	// æ¸…ç†å“åº”ï¼Œæå–JSONéƒ¨åˆ†
	jsonStart := strings.Index(response, "{")
	jsonEnd := strings.LastIndex(response, "}")

	var jsonContent string
	if jsonStart != -1 && jsonEnd != -1 && jsonEnd > jsonStart {
		jsonContent = response[jsonStart : jsonEnd+1]
	} else {
		jsonContent = response
	}

	// è§£æJSONå“åº”
	var result struct {
		Analysis      string                `json:"analysis"`
		ImpactLevel   string                `json:"impact_level"`
		ImpactScore   float64               `json:"impact_score"`
		ImpactScope   string                `json:"impact_scope"`
		RelatedTopics []string              `json:"related_topics"`
		AnalysisSteps []models.AnalysisStep `json:"analysis_steps"`
	}

	if err := json.Unmarshal([]byte(jsonContent), &result); err != nil {
		log.Printf("âš ï¸ JSONè§£æå¤±è´¥: %v, åŸå§‹å“åº”: %s", err, response)
		// å¦‚æœJSONè§£æå¤±è´¥ï¼Œè¿”å›é»˜è®¤å€¼
		return &EventAnalysisResult{
			Analysis:      response,
			ImpactLevel:   "medium",
			ImpactScore:   5.0,
			ImpactScope:   "å½±å“èŒƒå›´å¾…è¯„ä¼°",
			RelatedTopics: []string{},
			Steps:         []models.AnalysisStep{},
		}, nil
	}

	return &EventAnalysisResult{
		Analysis:      result.Analysis,
		ImpactLevel:   result.ImpactLevel,
		ImpactScore:   result.ImpactScore,
		ImpactScope:   result.ImpactScope,
		RelatedTopics: result.RelatedTopics,
		Steps:         result.AnalysisSteps,
	}, nil
}

// PredictTrends é¢„æµ‹è¶‹åŠ¿
func (p *OpenAICompatibleProvider) PredictTrends(content string, historicalData []models.News) ([]models.TrendPrediction, error) {
	// æ„å»ºå†å²æ•°æ®æ‘˜è¦
	historyContext := "å†å²æ•°æ®è¶‹åŠ¿ï¼š\n"
	for i, news := range historicalData {
		if i >= 5 { // åªå–æœ€è¿‘5æ¡
			break
		}
		historyContext += fmt.Sprintf("- %s: %s\n", news.PublishedAt.Format("2006-01-02"), news.Title)
	}

	prompt := fmt.Sprintf(`åŸºäºä»¥ä¸‹æ–°é—»å†…å®¹å’Œå†å²æ•°æ®ï¼Œé¢„æµ‹è¯¥äº‹ä»¶çš„æœªæ¥å‘å±•è¶‹åŠ¿ï¼š

å½“å‰æ–°é—»ï¼š
%s

%s

è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¿”å›é¢„æµ‹ç»“æœï¼š
[
  {
    "timeframe": "çŸ­æœŸï¼ˆ1-7å¤©ï¼‰",
    "trend": "è¶‹åŠ¿æè¿°",
    "probability": 0.0-1.0,
    "factors": ["å½±å“å› ç´ 1", "å½±å“å› ç´ 2"]
  },
  {
    "timeframe": "ä¸­æœŸï¼ˆ1-4å‘¨ï¼‰",
    "trend": "è¶‹åŠ¿æè¿°",
    "probability": 0.0-1.0,
    "factors": ["å½±å“å› ç´ 1", "å½±å“å› ç´ 2"]
  },
  {
    "timeframe": "é•¿æœŸï¼ˆ1-3æœˆï¼‰",
    "trend": "è¶‹åŠ¿æè¿°",
    "probability": 0.0-1.0,
    "factors": ["å½±å“å› ç´ 1", "å½±å“å› ç´ 2"]
  }
]`, content, historyContext)

	response, err := p.callAPI(prompt)
	if err != nil {
		return nil, err
	}

	// æ¸…ç†å“åº”ï¼Œæå–JSONæ•°ç»„éƒ¨åˆ†
	jsonStart := strings.Index(response, "[")
	jsonEnd := strings.LastIndex(response, "]")

	var jsonContent string
	if jsonStart != -1 && jsonEnd != -1 && jsonEnd > jsonStart {
		jsonContent = response[jsonStart : jsonEnd+1]
	} else {
		jsonContent = response
	}

	var predictions []models.TrendPrediction
	if err := json.Unmarshal([]byte(jsonContent), &predictions); err != nil {
		log.Printf("âš ï¸ è¶‹åŠ¿é¢„æµ‹JSONè§£æå¤±è´¥: %v, åŸå§‹å“åº”: %s", err, response)
		// è¿”å›é»˜è®¤é¢„æµ‹
		return []models.TrendPrediction{
			{
				Timeframe:   "çŸ­æœŸï¼ˆ1-7å¤©ï¼‰",
				Trend:       "äº‹æ€å°†æŒç»­å‘å±•",
				Probability: 0.7,
				Factors:     []string{"èˆ†è®ºå…³æ³¨åº¦", "æ”¿ç­–å½±å“"},
			},
		}, nil
	}

	return predictions, nil
}

// callAPI è°ƒç”¨API
func (p *OpenAICompatibleProvider) callAPI(prompt string) (string, error) {
	log.Printf("ğŸ¤– AI API è°ƒç”¨å¼€å§‹ - æ¨¡å‹: %s, baseURL: %s", p.model, p.baseURL)

	requestBody := map[string]interface{}{
		"model": p.model,
		"messages": []map[string]string{
			{
				"role":    "system",
				"content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–°é—»åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿æ–°é—»æ‘˜è¦ã€å…³é”®è¯æå–ã€äº‹ä»¶åˆ†æå’Œè¶‹åŠ¿é¢„æµ‹ã€‚",
			},
			{
				"role":    "user",
				"content": prompt,
			},
		},
		"temperature": p.temperature,
		"max_tokens":  p.maxTokens,
	}

	jsonData, err := json.Marshal(requestBody)
	if err != nil {
		log.Printf("âŒ JSONåºåˆ—åŒ–å¤±è´¥: %v", err)
		return "", err
	}

	log.Printf("ğŸ“¤ å‘é€è¯·æ±‚åˆ°: %s", p.baseURL+"/chat/completions")
	req, err := http.NewRequest("POST", p.baseURL+"/chat/completions", bytes.NewBuffer(jsonData))
	if err != nil {
		log.Printf("âŒ åˆ›å»ºHTTPè¯·æ±‚å¤±è´¥: %v", err)
		return "", err
	}

	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", "Bearer "+p.apiKey)

	// å®‰å…¨åœ°æ‰“å°API Keyçš„å‰å‡ ä½
	keyPreview := "æœªè®¾ç½®"
	if len(p.apiKey) > 0 {
		if len(p.apiKey) >= 10 {
			keyPreview = p.apiKey[:10] + "..."
		} else {
			keyPreview = p.apiKey[:len(p.apiKey)] + "..."
		}
	}
	log.Printf("ğŸ”‘ API Key: %s", keyPreview)

	// OpenRouterç‰¹æœ‰çš„è¯·æ±‚å¤´
	if p.siteURL != "" {
		req.Header.Set("HTTP-Referer", p.siteURL)
		log.Printf("ğŸŒ è®¾ç½®Referer: %s", p.siteURL)
	}
	if p.siteName != "" {
		req.Header.Set("X-Title", p.siteName)
		log.Printf("ğŸ“ è®¾ç½®ç«™ç‚¹åç§°: %s", p.siteName)
	}

	client := &http.Client{Timeout: time.Duration(p.timeout) * time.Second}
	start := time.Now()
	resp, err := client.Do(req)
	duration := time.Since(start)

	if err != nil {
		log.Printf("âŒ HTTPè¯·æ±‚å¤±è´¥ (è€—æ—¶: %v): %v", duration, err)
		return "", err
	}
	defer resp.Body.Close()

	log.Printf("ğŸ“¥ æ”¶åˆ°å“åº” - çŠ¶æ€ç : %d, è€—æ—¶: %v", resp.StatusCode, duration)

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		log.Printf("âŒ è¯»å–å“åº”ä½“å¤±è´¥: %v", err)
		return "", err
	}

	log.Printf("ğŸ“„ å“åº”ä½“é•¿åº¦: %d å­—èŠ‚", len(body))

	// å¦‚æœçŠ¶æ€ç ä¸æ˜¯200ï¼Œå…ˆæ‰“å°å“åº”ä½“ç”¨äºè°ƒè¯•
	if resp.StatusCode != 200 {
		log.Printf("âŒ HTTPé”™è¯¯ %d - å“åº”å†…å®¹: %s", resp.StatusCode, string(body))
		return "", fmt.Errorf("HTTP error %d: %s", resp.StatusCode, string(body))
	}

	var response struct {
		Choices []struct {
			Message struct {
				Content string `json:"content"`
			} `json:"message"`
		} `json:"choices"`
		Error struct {
			Message string `json:"message"`
			Type    string `json:"type"`
			Code    int    `json:"code"`
		} `json:"error"`
		Usage struct {
			PromptTokens     int `json:"prompt_tokens"`
			CompletionTokens int `json:"completion_tokens"`
			TotalTokens      int `json:"total_tokens"`
		} `json:"usage"`
	}

	if err := json.Unmarshal(body, &response); err != nil {
		log.Printf("âŒ JSONè§£æå¤±è´¥: %v - å“åº”å†…å®¹: %s", err, string(body))
		return "", err
	}

	if response.Error.Message != "" {
		log.Printf("âŒ APIè¿”å›é”™è¯¯: [%s] %s (code: %d)", response.Error.Type, response.Error.Message, response.Error.Code)
		return "", fmt.Errorf("API error [%s]: %s (code: %d)", response.Error.Type, response.Error.Message, response.Error.Code)
	}

	if len(response.Choices) > 0 {
		content := strings.TrimSpace(response.Choices[0].Message.Content)
		log.Printf("âœ… AIåˆ†ææˆåŠŸ - å†…å®¹é•¿åº¦: %d å­—ç¬¦, Tokenä½¿ç”¨: %d", len(content), response.Usage.TotalTokens)
		return content, nil
	}

	log.Printf("âŒ APIå“åº”æ— æœ‰æ•ˆå†…å®¹ - å“åº”: %s", string(body))
	return "", fmt.Errorf("no response from API")
}

// BatchAnalyzeUnprocessedNews æ‰¹é‡åˆ†ææœªå¤„ç†çš„æ–°é—»
func (s *AIService) BatchAnalyzeUnprocessedNews() error {
	log.Printf("[AI BATCH] å¼€å§‹æ‰¹é‡åˆ†ææœªå¤„ç†çš„æ–°é—»...")

	// æŸ¥æ‰¾æ²¡æœ‰AIåˆ†æç»“æœçš„æ–°é—»
	var newsWithoutAnalysis []models.News
	subQuery := s.db.Table("ai_analyses").
		Select("target_id").
		Where("type = ? AND status = ?", models.AIAnalysisTypeNews, "completed")

	err := s.db.Where("source_type = ? AND id NOT IN (?)", models.NewsTypeRSS, subQuery).
		Order("created_at DESC").
		Limit(50). // æ¯æ¬¡å¤„ç†50æ¡ï¼Œé¿å…è´Ÿè½½è¿‡é«˜
		Find(&newsWithoutAnalysis).Error

	if err != nil {
		log.Printf("[AI BATCH ERROR] æŸ¥è¯¢æœªåˆ†ææ–°é—»å¤±è´¥: %v", err)
		return err
	}

	if len(newsWithoutAnalysis) == 0 {
		log.Printf("[AI BATCH] æ²¡æœ‰éœ€è¦åˆ†æçš„æ–°é—»")
		return nil
	}

	log.Printf("[AI BATCH] æ‰¾åˆ° %d æ¡éœ€è¦åˆ†æçš„æ–°é—»", len(newsWithoutAnalysis))

	successCount := 0
	for i, news := range newsWithoutAnalysis {
		log.Printf("[AI BATCH] åˆ†ææ–°é—» %d/%d: %s", i+1, len(newsWithoutAnalysis), news.Title)

		analysisReq := models.AIAnalysisRequest{
			Type:     models.AIAnalysisTypeNews,
			TargetID: news.ID,
			Options: struct {
				EnableSummary     bool `json:"enable_summary"`
				EnableKeywords    bool `json:"enable_keywords"`
				EnableSentiment   bool `json:"enable_sentiment"`
				EnableTrends      bool `json:"enable_trends"`
				EnableImpact      bool `json:"enable_impact"`
				ShowAnalysisSteps bool `json:"show_analysis_steps"`
			}{
				EnableSummary:   true,
				EnableKeywords:  true,
				EnableSentiment: true,
				EnableTrends:    false, // æ‰¹é‡å¤„ç†æ—¶å…³é—­è¶‹åŠ¿åˆ†æï¼Œæé«˜é€Ÿåº¦
				EnableImpact:    false, // æ‰¹é‡å¤„ç†æ—¶å…³é—­å½±å“åˆ†æï¼Œæé«˜é€Ÿåº¦
			},
		}

		// åŒæ­¥æ‰§è¡Œï¼Œé¿å…å¹¶å‘è¿‡å¤š
		if _, err := s.AnalyzeNews(news.ID, analysisReq); err != nil {
			log.Printf("[AI BATCH WARNING] åˆ†ææ–°é—» %d å¤±è´¥: %v", news.ID, err)
		} else {
			successCount++
			log.Printf("[AI BATCH] æˆåŠŸåˆ†ææ–°é—» %d", news.ID)
		}

		// æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
		time.Sleep(2 * time.Second)
	}

	log.Printf("[AI BATCH] æ‰¹é‡åˆ†æå®Œæˆ: æˆåŠŸ %d/%d", successCount, len(newsWithoutAnalysis))
	return nil
}

// AnalyzeNewsWithRetry å¸¦é‡è¯•æœºåˆ¶çš„æ–°é—»AIåˆ†æ
func (s *AIService) AnalyzeNewsWithRetry(newsID uint, maxRetries int) {
	analysisReq := models.AIAnalysisRequest{
		Type:     models.AIAnalysisTypeNews,
		TargetID: newsID,
		Options: struct {
			EnableSummary     bool `json:"enable_summary"`
			EnableKeywords    bool `json:"enable_keywords"`
			EnableSentiment   bool `json:"enable_sentiment"`
			EnableTrends      bool `json:"enable_trends"`
			EnableImpact      bool `json:"enable_impact"`
			ShowAnalysisSteps bool `json:"show_analysis_steps"`
		}{
			EnableSummary:   true,
			EnableKeywords:  true,
			EnableSentiment: true,
			EnableTrends:    false, // RSSå®æ—¶åˆ†ææ—¶å…³é—­è¶‹åŠ¿åˆ†æï¼Œæé«˜é€Ÿåº¦
			EnableImpact:    false, // RSSå®æ—¶åˆ†ææ—¶å…³é—­å½±å“åˆ†æï¼Œæé«˜é€Ÿåº¦
		},
	}

	for attempt := 1; attempt <= maxRetries; attempt++ {
		if _, err := s.AnalyzeNews(newsID, analysisReq); err != nil {
			log.Printf("[AI WARNING] AIåˆ†æå¤±è´¥ (å°è¯• %d/%d): æ–°é—»ID %d, é”™è¯¯: %v", attempt, maxRetries, newsID, err)
			if attempt < maxRetries {
				// ç­‰å¾…åé‡è¯•ï¼ˆæŒ‡æ•°é€€é¿ï¼‰
				waitTime := time.Duration(attempt) * 5 * time.Second
				log.Printf("[AI DEBUG] ç­‰å¾… %v åé‡è¯•AIåˆ†æ...", waitTime)
				time.Sleep(waitTime)
			}
		} else {
			log.Printf("[AI DEBUG] AIåˆ†ææˆåŠŸ: æ–°é—»ID %d (å°è¯• %d/%d)", newsID, attempt, maxRetries)
			return
		}
	}

	log.Printf("[AI ERROR] AIåˆ†ææœ€ç»ˆå¤±è´¥: æ–°é—»ID %d, å·²é‡è¯• %d æ¬¡", newsID, maxRetries)
}
